{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference about effect sizes (IN PROGRESS)\n",
    "This notebook is going to explore any mistaken research conclusions that may arise from use of the original Rachlin discount function, aand compare that to the Modified Rachlin function.\n",
    "\n",
    "We will do this in the context of comparing two groups with different discount rates $\\kappa$. We will explore a range of true effect sizes (difference in means of 2 groups divided by pooled variance).\n",
    "\n",
    "Steps are:\n",
    "\n",
    "1. Define true group means of $\\kappa$.\n",
    "2. Define a range of true effect sizes, varying the variance of $\\kappa$ for each group accordingly.\n",
    "3. Iterate over each true effect size:\n",
    "    - simulate a dataset of $N$ participants\n",
    "    - conduct Bayesian inference to estimate effect sizes, doing so for the Rachlin and the Modified Rachlin discount functions.\n",
    "    - plot the true effect size vs the inferred effect size.\n",
    "    \n",
    "**The example below is with differences in group $\\kappa$ values, but no group difference in group $s$ values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the Bayesian t-test component of this code was inspired by the PyMC3 implementation (here https://github.com/strawlab/best, https://docs.pymc.io/notebooks/BEST.html) of the BEST model by Kruschke (2012)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "print(f'Python version:\\n{sys.version}\\n')\n",
    "\n",
    "import pymc3 as pm\n",
    "print(f'PyMC3 v{pm.__version__}')\n",
    "\n",
    "%run set_plot_options.py\n",
    "from discount_functions import rachlin, rachlin_kappa\n",
    "from adaptive_experiment import make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random number generator\n",
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Define sampler options\n",
    "sample_options = {'tune': 1000, 'draws': 2000,\n",
    "                  'chains': 4, 'cores': 4,\n",
    "                  'nuts_kwargs': {'target_accept': 0.95},\n",
    "                  'random_seed': SEED}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define inference method as `MCMC` or `variational inference`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFERENCE_METHOD = 'MCMC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for simulated dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohend(d1, d2):\n",
    "    # calculate the size of samples\n",
    "    n1, n2 = len(d1), len(d2)\n",
    "    # calculate the variance of the samples\n",
    "    s1, s2 = np.var(d1, ddof=1), np.var(d2, ddof=1)\n",
    "    # calculate the pooled standard deviation\n",
    "    s = math.sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))\n",
    "    # calculate the means of the samples\n",
    "    u1, u2 = np.mean(d1), np.mean(d2)\n",
    "    # calculate the effect size\n",
    "    return (u1 - u2) / s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_participant_level_dataset(logκ_std,\n",
    "                                   groupA_logκmean=-4.6, \n",
    "                                   groupB_logκmean=-2.3,\n",
    "                                   groupA_logsmean=0., \n",
    "                                   groupB_logsmean=0.,\n",
    "                                   logs_std=0.1,\n",
    "                                   N_per_group=10):\n",
    "    '''Generate a set of true participant discount function parameter\n",
    "    values which conforms to the inputs:\n",
    "    - group means\n",
    "    - effect size'''\n",
    "    \n",
    "    # generate log(κ) values\n",
    "    a_logκ = np.random.normal(loc=groupA_logκmean, scale=logκ_std, size=N_per_group)\n",
    "    b_logκ = np.random.normal(loc=groupB_logκmean, scale=logκ_std, size=N_per_group)\n",
    "    \n",
    "    # generate log(s) values\n",
    "    a_logs = np.random.normal(loc=groupA_logsmean, scale=logs_std, size=N_per_group)\n",
    "    b_logs = np.random.normal(loc=groupB_logsmean, scale=logs_std, size=N_per_group)\n",
    "    \n",
    "    dataset = pd.DataFrame()\n",
    "    dataset['logkappa'] = np.concatenate([a_logκ, b_logκ])\n",
    "    dataset['logs'] = np.concatenate([a_logs, b_logs])\n",
    "    dataset['group'] = np.concatenate( (np.zeros(N_per_group), np.ones(N_per_group)))\n",
    "    # convert to int\n",
    "    dataset['group'] = np.int_(dataset['group'])\n",
    "    \n",
    "    true_logκ_effect_size = cohend(a_logκ, b_logκ)\n",
    "    true_logs_effect_size = cohend(a_logs, b_logs)\n",
    "    \n",
    "    return dataset, true_logκ_effect_size, true_logs_effect_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_apply_combine(df, func):\n",
    "    '''Ben's useful split-apply-combine utility function.\n",
    "    We split by row, iterate over them applying the function, then combine into a\n",
    "    single dataframe.'''\n",
    "    output = []\n",
    "    for i in range(df.shape[0]):\n",
    "        # split by row\n",
    "        row = df.iloc[i,:]\n",
    "        # apply function\n",
    "        output.append(func(row, i))\n",
    "        \n",
    "    # combine\n",
    "    output = pd.concat(output, ignore_index=True)\n",
    "    return output\n",
    "\n",
    "\n",
    "def simulate_one_experiment(row, i):\n",
    "    \n",
    "    data_generating_discount_func = rachlin_kappa\n",
    "    \n",
    "    # extract info from row (HERE IS WHERE WE CONVERT PARAMETERS FROM LOG TO LINEAR SPACE)\n",
    "    data_generating_params = np.exp(row.logs), np.exp(row.logkappa)\n",
    "    \n",
    "    # apply my function... simulate a dataset\n",
    "    pdata = make_dataset(data_generating_discount_func, data_generating_params)\n",
    "    \n",
    "    # add participant number column\n",
    "    pdata['id'] = pd.Series(i, index=pdata.index)\n",
    "    \n",
    "    # add group column\n",
    "    group = row.group\n",
    "    pdata['group'] = np.int_(pd.Series(group, index=pdata.index))\n",
    "    \n",
    "    return pdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_entire_experiment(participant_level_dataset):\n",
    "    '''Simulate an entire experiment based on the provided true participant level\n",
    "    parameters.'''\n",
    "    trial_level_dataset = split_apply_combine(participant_level_dataset, simulate_one_experiment)\n",
    "    return trial_level_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Bayesian inference on effect size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_rachlin(delay, k, s):\n",
    "    ''' This is the MODIFIED Rachlin discount function.'''\n",
    "    return 1 / (1.0+(k*delay)**s)\n",
    "\n",
    "\n",
    "def rachlin(delay, k, s):\n",
    "    ''' This is the original Rachlin discount function.'''\n",
    "    return 1 / (1.0+k*delay**s)\n",
    "\n",
    "\n",
    "def Φ(VA, VB, ϵ=0.01):\n",
    "    '''Psychometric function which converts the decision variable (VB-VA)\n",
    "    into a reponse probability. Output corresponds to probability of choosing\n",
    "    the delayed reward (option B).'''\n",
    "    return ϵ + (1.0-2.0*ϵ) * (1/(1+pm.math.exp(-1.7*(VB-VA))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Update the Φ function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def participant_group_lookup(trial_level_dataset):\n",
    "    # create a group lookup table. 1 entry for each particpant\n",
    "    temp = np.array([trial_level_dataset['id'].values, trial_level_dataset['group'].values]).T\n",
    "    temp = np.unique(temp, axis=0)\n",
    "    group = temp[:,1]\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_modified_rachlin_model(trial_level_dataset):\n",
    "    '''Returns a PyMC3 model which does inference on discounting parameters from participants\n",
    "    from two groups. We have hierachical inference at the group level and we are essentially doing\n",
    "    a Bayesian t-test where we estimate Cohen's D effect size'''\n",
    "    \n",
    "    # extract data from DataFrame\n",
    "    DA = trial_level_dataset.DA.values\n",
    "    RA = trial_level_dataset.RA.values\n",
    "    DB = trial_level_dataset.DB.values\n",
    "    RB = trial_level_dataset.RB.values\n",
    "    R = trial_level_dataset.R.values\n",
    "    id = trial_level_dataset.id.values\n",
    "    \n",
    "    group = participant_group_lookup(trial_level_dataset)\n",
    "    \n",
    "    n1, n2 = sum(group==0), sum(group==1)\n",
    "    \n",
    "    n_participants = np.max(trial_level_dataset.id) + 1\n",
    "    n_groups = 2\n",
    "     \n",
    "#     # use actual mean and std as parameters for the prior\n",
    "#     μ_m = y.value.mean()\n",
    "#     μ_s = y.value.std() * 2\n",
    "\n",
    "    σ_low = 0\n",
    "    σ_high = 10\n",
    "    \n",
    "    # Start building the model from the top down, starting with Bayesian t-test\n",
    "    with pm.Model() as model:\n",
    "        logκ_group_means = pm.Normal('logκ_group_means', mu=-3, sd=2, shape=n_groups)\n",
    "        logκ_group_stds = pm.Uniform('logκ_group_stds', lower=σ_low, upper=σ_high, shape=n_groups)\n",
    "        # group_logk = pm.Normal('group_logk', mu=group_means, sd=group_stds, shape=n_groups)\n",
    "\n",
    "        logs_group_means = pm.Normal('logs_group_means', mu=1, sd=1, shape=n_groups)\n",
    "        logs_group_stds = pm.Uniform('logs_group_stds', lower=σ_low, upper=σ_high, shape=n_groups)\n",
    "            \n",
    "    # compute measures about the group level estimates of logk\n",
    "    with model:\n",
    "        logκ_diff_of_means = pm.Deterministic('logκ difference of means', logκ_group_means[0] - logκ_group_means[1])\n",
    "        logκ_diff_of_stds = pm.Deterministic('logκ difference of stds', logκ_group_stds[0] - logκ_group_stds[1])\n",
    "        logκ_effect_size = pm.Deterministic('logκ effect size',\n",
    "                                            logκ_diff_of_means / np.sqrt(((n1-1)*logκ_group_stds[0]**2 + (n2-1) *logκ_group_stds[1]**2) / (n1 + n2 - 2)))\n",
    "        \n",
    "        logs_diff_of_means = pm.Deterministic('logs difference of means', logs_group_means[0] - logs_group_means[1])\n",
    "        logs_diff_of_stds = pm.Deterministic('logs difference of stds', logs_group_stds[0] - logs_group_stds[1])\n",
    "        logs_effect_size = pm.Deterministic('logs effect size',\n",
    "                                            logs_diff_of_means / np.sqrt(((n1-1)*logs_group_stds[0]**2 + (n2-1) *logs_group_stds[1]**2) / (n1 + n2 - 2)))\n",
    "        \n",
    "#         logκ_diff_of_means = pm.Deterministic('logκ difference of means', logκ_group_means[0] - logκ_group_means[1])\n",
    "#         logκ_diff_of_stds = pm.Deterministic('logκ difference of stds', logκ_group_stds[0] - logκ_group_stds[1])\n",
    "#         logκ_effect_size = pm.Deterministic('logκ effect size',\n",
    "#                                        logκ_diff_of_means / np.sqrt((logκ_group_stds[0]**2 + logκ_group_stds[1]**2) / 2))\n",
    "        \n",
    "#         logs_diff_of_means = pm.Deterministic('logs difference of means', logs_group_means[0] - logs_group_means[1])\n",
    "#         logs_diff_of_stds = pm.Deterministic('logs difference of stds', logs_group_stds[0] - logs_group_stds[1])\n",
    "#         logs_effect_size = pm.Deterministic('logs effect size',\n",
    "#                                        logs_diff_of_means / np.sqrt((logs_group_stds[0]**2 + logs_group_stds[1]**2) / 2))\n",
    "        \n",
    "        \n",
    "    # Discounting part of the model\n",
    "    with model:\n",
    "        # priors over parameters for each participant\n",
    "        logκ = pm.Normal('logκ', mu=logκ_group_means[group], sd=logκ_group_stds[group], shape=n_participants)\n",
    "        logs = pm.Normal('logs', mu=logs_group_means[group], sd=logs_group_stds[group], shape=n_participants)\n",
    "    \n",
    "        VA = RA * modified_rachlin(DA, pm.math.exp(logκ[id]), pm.math.exp(logs[id]))  \n",
    "        VB = RB * modified_rachlin(DB, pm.math.exp(logκ[id]), pm.math.exp(logs[id]))  \n",
    "\n",
    "        P = pm.Deterministic('P', Φ(VA, VB))\n",
    "\n",
    "        # Likelihood of observations\n",
    "        R = pm.Bernoulli('R', p=P, observed=R)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rachlin_model(trial_level_dataset):\n",
    "    '''Returns a PyMC3 model which does inference on discounting parameters from participants\n",
    "    from two groups. We have hierachical inference at the group level and we are essentially doing\n",
    "    a Bayesian t-test where we estimate Cohen's D effect size'''\n",
    "    \n",
    "    # DEFINE OBSERVED DATA ===========================================\n",
    "    DA = trial_level_dataset.DA.values\n",
    "    RA = trial_level_dataset.RA.values\n",
    "    DB = trial_level_dataset.DB.values\n",
    "    RB = trial_level_dataset.RB.values\n",
    "    R = trial_level_dataset.R.values\n",
    "    id = trial_level_dataset.id.values\n",
    "    \n",
    "    group = participant_group_lookup(trial_level_dataset)\n",
    "    \n",
    "    n1, n2 = sum(group==0), sum(group==1)\n",
    "    n_participants = np.max(trial_level_dataset.id) + 1\n",
    "    n_groups = 2\n",
    "    \n",
    "    # BUILD MODEL ====================================================\n",
    "     \n",
    "#     # use actual mean and std as parameters for the prior\n",
    "#     μ_m = y.value.mean()\n",
    "#     μ_s = y.value.std() * 2\n",
    "\n",
    "    σ_low = 0\n",
    "    σ_high = 10\n",
    "    \n",
    "    # Start building the model from the top down, starting with Bayesian t-test\n",
    "    with pm.Model() as model:\n",
    "        logk_group_means = pm.Normal('logk_group_means', mu=-3, sd=2, shape=n_groups)\n",
    "        logk_group_stds = pm.Uniform('logk_group_stds', lower=σ_low, upper=σ_high, shape=n_groups)\n",
    "        # group_logk = pm.Normal('group_logk', mu=group_means, sd=group_stds, shape=n_groups)\n",
    "\n",
    "        logs_group_means = pm.Normal('logs_group_means', mu=1, sd=1, shape=n_groups)\n",
    "        logs_group_stds = pm.Uniform('logs_group_stds', lower=σ_low, upper=σ_high, shape=n_groups)\n",
    "            \n",
    "    # compute measures about the group level estimates of logk\n",
    "    with model:\n",
    "        logk_diff_of_means = pm.Deterministic('logk difference of means', logk_group_means[0] - logk_group_means[1])\n",
    "        logk_diff_of_stds = pm.Deterministic('logk difference of stds', logk_group_stds[0] - logk_group_stds[1])\n",
    "        logk_effect_size = pm.Deterministic('logk effect size',\n",
    "                                            logk_diff_of_means / np.sqrt(((n1-1)*logk_group_stds[0]**2 + (n2-1) *logk_group_stds[1]**2) / (n1 + n2 - 2)))\n",
    "        \n",
    "        logs_diff_of_means = pm.Deterministic('logs difference of means', logs_group_means[0] - logs_group_means[1])\n",
    "        logs_diff_of_stds = pm.Deterministic('logs difference of stds', logs_group_stds[0] - logs_group_stds[1])\n",
    "        logs_effect_size = pm.Deterministic('logs effect size',\n",
    "                                            logs_diff_of_means / np.sqrt(((n1-1)*logs_group_stds[0]**2 + (n2-1) *logs_group_stds[1]**2) / (n1 + n2 - 2)))\n",
    "        \n",
    "#         logk_diff_of_means = pm.Deterministic('logk difference of means', logk_group_means[0] - logk_group_means[1])\n",
    "#         logk_diff_of_stds = pm.Deterministic('logk difference of stds', logk_group_stds[0] - logk_group_stds[1])\n",
    "#         logk_effect_size = pm.Deterministic('logk effect size',\n",
    "#                                        logk_diff_of_means / np.sqrt((logk_group_stds[0]**2 + logk_group_stds[1]**2) / 2))\n",
    "        \n",
    "#         logs_diff_of_means = pm.Deterministic('logs difference of means', logs_group_means[0] - logs_group_means[1])\n",
    "#         logs_diff_of_stds = pm.Deterministic('logs difference of stds', logs_group_stds[0] - logs_group_stds[1])\n",
    "#         logs_effect_size = pm.Deterministic('logs effect size',\n",
    "#                                        logs_diff_of_means / np.sqrt((logs_group_stds[0]**2 + logs_group_stds[1]**2) / 2))\n",
    "        \n",
    "        \n",
    "    # Discounting part of the model\n",
    "    with model:\n",
    "        # priors over parameters for each participant\n",
    "        logk = pm.Normal('logκ', mu=logk_group_means[group], sd=logk_group_stds[group], shape=n_participants)\n",
    "        logs = pm.Normal('logs', mu=logs_group_means[group], sd=logs_group_stds[group], shape=n_participants)\n",
    "    \n",
    "        VA = RA * rachlin(DA, pm.math.exp(logk[id]), pm.math.exp(logs[id]))  \n",
    "        VB = RB * rachlin(DB, pm.math.exp(logk[id]), pm.math.exp(logs[id]))  \n",
    "\n",
    "        P = pm.Deterministic('P', Φ(VA, VB))\n",
    "\n",
    "        # Likelihood of observations\n",
    "        R = pm.Bernoulli('R', p=P, observed=R)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group = participant_group_lookup(trial_level_dataset)\n",
    "# n1, n2 = sum(group==0), sum(group==1)\n",
    "# n1, n2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High level code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_effect_size(trial_level_dataset, df=None, debug=False):\n",
    "    \n",
    "    # Build model\n",
    "    if df == 'modified rachlin':\n",
    "        model = make_modified_rachlin_model(trial_level_dataset)\n",
    "    elif df == 'rachlin':\n",
    "        model = make_rachlin_model(trial_level_dataset)\n",
    "    elif df is None:\n",
    "        print('ERROR: Need to specify the df correctly')\n",
    "    \n",
    "    if debug:\n",
    "        pm.model_to_graphviz(model)\n",
    "    \n",
    "    # Do the inference\n",
    "    if INFERENCE_METHOD == 'variational inference':\n",
    "        with model:\n",
    "            advi_fit = pm.fit(method=pm.ADVI(), n=100_000)\n",
    "            \n",
    "            advi_elbo = pd.DataFrame({'log-ELBO': -np.log(advi_fit.hist),\n",
    "                          'n': np.arange(advi_fit.hist.shape[0])})\n",
    "            plt.plot(advi_elbo['n'], advi_elbo['log-ELBO'])\n",
    "\n",
    "            trace = advi_fit.sample(10_000)\n",
    "    \n",
    "    elif INFERENCE_METHOD == 'MCMC':\n",
    "        with model:\n",
    "            trace = pm.sample(**sample_options)\n",
    "        \n",
    "    # Calculate summary statistics\n",
    "    if df == 'modified rachlin':\n",
    "        logκ = pm.stats.quantiles(trace['logκ effect size'])\n",
    "        logs = pm.stats.quantiles(trace['logs effect size'])\n",
    "        # package results into a single row of a DataFrame\n",
    "        return pd.DataFrame.from_dict({'logκ50': [logκ[50]], 'logκ2.5': [logκ[2.5]], 'logκ97.5': [logκ[97.5]],\n",
    "                                       'logs50': [logs[50]], 'logs2.5': [logs[2.5]], 'logs97.5': [logs[97.5]]})\n",
    "    elif df == 'rachlin':\n",
    "        logk = pm.stats.quantiles(trace['logk effect size'])\n",
    "        logs = pm.stats.quantiles(trace['logs effect size'])\n",
    "        # package results into a single row of a DataFrame\n",
    "        return pd.DataFrame.from_dict({'logk50': [logk[50]], 'logk2.5': [logk[2.5]], 'logk97.5': [logk[97.5]],\n",
    "                                       'logs50': [logs[50]], 'logs2.5': [logs[2.5]], 'logs97.5': [logs[97.5]]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over κstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: low std means high effect size\n",
    "group_κstd_list = np.linspace(0.5, 8, 6)\n",
    "\n",
    "results_modified_rachlin = []\n",
    "results_rachlin = []\n",
    "\n",
    "for group_logκstd in group_κstd_list:\n",
    "\n",
    "    # INFER EFFECT SIZES FOR GIVEN SET OF GROUP PARAMETERS\n",
    "\n",
    "    pdataset, true_logκ_effect_size, true_logs_effect_size = make_participant_level_dataset(group_logκstd,\n",
    "                                       groupA_logκmean=np.log(10**-1), \n",
    "                                       groupB_logκmean=np.log(10**-2),\n",
    "                                       groupA_logsmean=0, \n",
    "                                       groupB_logsmean=0,\n",
    "                                       logs_std=1,\n",
    "                                       N_per_group=20)\n",
    "\n",
    "    trial_level_dataset = simulate_entire_experiment(pdataset)\n",
    "\n",
    "    # Inferences for modified rachlin\n",
    "    these_results = infer_effect_size(trial_level_dataset, df='modified rachlin')\n",
    "    these_results['logκstd'] = group_logκstd\n",
    "    these_results['true_logκ_effect_size'] = true_logκ_effect_size\n",
    "    these_results['true_logs_effect_size'] = true_logs_effect_size\n",
    "    results_modified_rachlin.append(these_results)\n",
    "    \n",
    "    # Inferences for rachlin\n",
    "    these_results = infer_effect_size(trial_level_dataset, df='rachlin')\n",
    "    these_results['logkstd'] = group_logκstd\n",
    "    these_results['true_logκ_effect_size'] = true_logκ_effect_size\n",
    "    these_results['true_logs_effect_size'] = true_logs_effect_size\n",
    "    results_rachlin.append(these_results)\n",
    "    \n",
    "results_modified_rachlin = pd.concat(results_modified_rachlin, ignore_index=True)\n",
    "results_rachlin = pd.concat(results_rachlin, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_modified_rachlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rachlin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "# LOG KAPPA PLOT ------------------------------------------------\n",
    "ax.errorbar(results_modified_rachlin['true_logκ_effect_size'],\n",
    "               results_modified_rachlin['logκ50'], \n",
    "               yerr=[results_modified_rachlin['logκ2.5']-results_modified_rachlin['logκ50'],\n",
    "                     results_modified_rachlin['logκ50']-results_modified_rachlin['logκ97.5']], \n",
    "               fmt='-o', \n",
    "               label='modified Rachlin')\n",
    "\n",
    "ax.errorbar(results_rachlin['true_logκ_effect_size'],\n",
    "               results_rachlin['logk50'], \n",
    "               yerr=[results_rachlin['logk2.5']-results_rachlin['logk50'],\n",
    "                     results_rachlin['logk50']-results_rachlin['logk97.5']], \n",
    "               fmt='-o', \n",
    "               label='original Rachlin')\n",
    "\n",
    "# ax.spines['bottom'].set_position(('data',0))\n",
    "ax.axhline(y=0, linewidth=1.5, c='k', ls='--')\n",
    "\n",
    "ax.plot([0, 5], [0, 5], c='k')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "ax.set(xlabel=\"True empirical effect size, Cohen's D\", \n",
    "       ylabel=\"Inferred effect size, Cohen's D\", \n",
    "       title='log(κ)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test code to do inference for a given effect size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_logκstd = 0.01\n",
    "\n",
    "participant_level_dataset, true_κ_effect_size, true_s_effect_size = make_participant_level_dataset(group_logκstd,\n",
    "                                   groupA_logκmean=-4.6, \n",
    "                                   groupB_logκmean=-2.3,\n",
    "                                   groupA_logsmean=0, \n",
    "                                   groupB_logsmean=0,\n",
    "                                   logs_std=0.1,\n",
    "                                   N_per_group=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_level_dataset = simulate_entire_experiment(participant_level_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function above will replace the code below after it's all good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_modified_rachlin_model(trial_level_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO THE INFERENCE\n",
    "with model:\n",
    "    trace = pm.sample(**sample_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.energyplot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace, var_names=['logκ'], r_hat=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace, var_names=['logs'], r_hat=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace, var_names=['logκ_group_means', 'logκ_group_stds']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace, var_names=['logs_group_means', 'logs_group_stds'], r_hat=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace, var_names=['logκ difference of means','logκ difference of stds', 'logκ effect size'],\n",
    "                  ref_val=0,\n",
    "                  color='#87ceeb');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace, var_names=['logs difference of means','logs difference of stds', 'logs effect size'],\n",
    "                  ref_val=0,\n",
    "                  color='#87ceeb');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO extract mean and CI for effect size for logk and logs\n",
    "# wrap that into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logκ_stats = pm.stats.quantiles(trace['logκ effect size'])\n",
    "logs_stats = pm.stats.quantiles(trace['logs effect size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_stats = pm.stats.quantiles(trace['logs effect size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_logκstd = 0.01\n",
    "\n",
    "participant_level_dataset, true_κ_effect_size, true_s_effect_size = make_participant_level_dataset(group_logκstd,\n",
    "                                   groupA_logκmean=-4.6, \n",
    "                                   groupB_logκmean=-2.3,\n",
    "                                   groupA_logsmean=0, \n",
    "                                   groupB_logsmean=0,\n",
    "                                   logs_std=0.1,\n",
    "                                   N_per_group=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_level_dataset = simulate_entire_experiment(participant_level_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_modified_rachlin_model(trial_level_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    advi_fit = pm.fit(method=pm.ADVI(), n=60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advi_elbo = pd.DataFrame({'log-ELBO': -np.log(advi_fit.hist),\n",
    "                          'n': np.arange(advi_fit.hist.shape[0])})\n",
    "plt.plot(advi_elbo['n'], advi_elbo['log-ELBO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advi_trace = advi_fit.sample(10000)\n",
    "#pm.traceplot(advi_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(advi_trace, var_names=['logκ effect size', 'logs effect size'],\n",
    "                  ref_val=0, color='#87ceeb');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- Kruschke, John. (2012) Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
