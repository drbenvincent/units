{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference about effect sizes (IN PROGRESS)\n",
    "This notebook is going to explore any mistaken research conclusions that may arise from use of the original Rachlin discount function, aand compare that to the Modified Rachlin function.\n",
    "\n",
    "We will do this in the context of comparing two groups with different discount rates $\\kappa$. We will explore a range of true effect sizes (difference in means of 2 groups divided by pooled variance).\n",
    "\n",
    "Steps are:\n",
    "\n",
    "1. Define true group means of $\\kappa$.\n",
    "2. Define a range of true effect sizes, varying the variance of $\\kappa$ for each group accordingly.\n",
    "3. Iterate over each true effect size:\n",
    "    - simulate a dataset of $N$ participants\n",
    "    - conduct Bayesian inference to estimate effect sizes, doing so for the Rachlin and the Modified Rachlin discount functions.\n",
    "    - plot the true effect size vs the inferred effect size.\n",
    "    \n",
    "**The example below is with differences in group $\\kappa$ values, but no group difference in group $s$ values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the Bayesian t-test component of this code was inspired by the PyMC3 implementation (here https://github.com/strawlab/best, https://docs.pymc.io/notebooks/BEST.html) of the BEST model by Kruschke (2012)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# import sys\n",
    "# print(\"Python version:\\n{}\\n\".format(sys.version))\n",
    "\n",
    "import pymc3 as pm\n",
    "print(f'PyMC3 v{pm.__version__}')\n",
    "\n",
    "%run set_plot_options.py\n",
    "from discount_functions import rachlin, rachlin_kappa\n",
    "from adaptive_experiment import make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random number generator\n",
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Define sampler options\n",
    "sample_options = {'tune': 500, 'draws': 1000,\n",
    "                  'chains': 4, 'cores': 2,\n",
    "                  'nuts_kwargs': {'target_accept': 0.95},\n",
    "                  'random_seed': SEED}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for simulated dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohend(d1, d2):\n",
    "    # calculate the size of samples\n",
    "    n1, n2 = len(d1), len(d2)\n",
    "    # calculate the variance of the samples\n",
    "    s1, s2 = np.var(d1, ddof=1), np.var(d2, ddof=1)\n",
    "    # calculate the pooled standard deviation\n",
    "    s = math.sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))\n",
    "    # calculate the means of the samples\n",
    "    u1, u2 = np.mean(d1), np.mean(d2)\n",
    "    # calculate the effect size\n",
    "    return (u1 - u2) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_participant_level_dataset(logκ_std,\n",
    "                                   groupA_logκmean=-4.6, \n",
    "                                   groupB_logκmean=-2.3,\n",
    "                                   groupA_logsmean=0, \n",
    "                                   groupB_logsmean=0,\n",
    "                                   logs_std=0.1,\n",
    "                                   N_per_group=20):\n",
    "    '''Generate a set of true participant discount function parameter\n",
    "    values which conforms to the inputs:\n",
    "    - group means\n",
    "    - effect size'''\n",
    "    \n",
    "    # generate log(κ) values\n",
    "    a_logκ = np.random.normal(loc=groupA_logκmean, scale=logκ_std, size=N_per_group)\n",
    "    b_logκ = np.random.normal(loc=groupB_logκmean, scale=logκ_std, size=N_per_group)\n",
    "    \n",
    "    # generate log(s) values\n",
    "    a_logs = np.random.normal(loc=groupA_logsmean, scale=logs_std, size=N_per_group)\n",
    "    b_logs = np.random.normal(loc=groupB_logsmean, scale=logs_std, size=N_per_group)\n",
    "    \n",
    "    dataset = pd.DataFrame()\n",
    "    dataset['logkappa'] = np.concatenate([a_logκ, b_logκ])\n",
    "    dataset['logs'] = np.concatenate([a_logs, b_logs])\n",
    "    dataset['group'] = np.concatenate( (np.zeros(N_per_group), np.ones(N_per_group)))\n",
    "    # convert to int\n",
    "    dataset['group'] = np.int_(dataset['group'])\n",
    "    \n",
    "    true_logκ_effect_size = cohend(a_logκ, b_logκ)\n",
    "    \n",
    "    return dataset, true_logκ_effect_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_apply_combine(df, func):\n",
    "    '''Ben's useful split-apply-combine utility function.\n",
    "    We split by row, iterate over them applying the function, then combine into a\n",
    "    single dataframe.'''\n",
    "    output = []\n",
    "    for i in range(df.shape[0]):\n",
    "        # split by row\n",
    "        row = df.iloc[i,:]\n",
    "        # apply function\n",
    "        output.append(func(row, i))\n",
    "        \n",
    "    # combine\n",
    "    output = pd.concat(output, ignore_index=True)\n",
    "    return output\n",
    "\n",
    "\n",
    "def simulate_one_experiment(row, i):\n",
    "    \n",
    "    data_generating_discount_func = rachlin_kappa\n",
    "    \n",
    "    # extract info from row (HERE IS WHERE WE CONVERT PARAMETERS FROM LOG TO LINEAR SPACE)\n",
    "    data_generating_params = np.exp(row.logs), np.exp(row.logkappa)\n",
    "    \n",
    "    # apply my function... simulate a dataset\n",
    "    pdata = make_dataset(data_generating_discount_func, data_generating_params)\n",
    "    \n",
    "    # add participant number column\n",
    "    pdata['id'] = pd.Series(i, index=pdata.index)\n",
    "    \n",
    "    # add group column\n",
    "    group = row.group\n",
    "    pdata['group'] = np.int_(pd.Series(group, index=pdata.index))\n",
    "    \n",
    "    return pdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_entire_experiment(participant_level_dataset):\n",
    "    '''Simulate an entire experiment based on the provided true participant level\n",
    "    parameters.'''\n",
    "    trial_level_dataset = split_apply_combine(participant_level_dataset, simulate_one_experiment)\n",
    "    return trial_level_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Bayesian inference on effect size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def V(reward, delay, logk, logs):\n",
    "    '''Calculate the present subjective value of a given prospect'''\n",
    "    k = pm.math.exp(logk)\n",
    "    s = pm.math.exp(logs)\n",
    "    return reward * modified_rachlin(delay, k, s)\n",
    "\n",
    "\n",
    "def modified_rachlin(delay, k, s):\n",
    "    ''' This is the MODIFIED Rachlin discount function.'''\n",
    "    return 1 / (1.0+(k*delay)**s)\n",
    "\n",
    "\n",
    "def Φ(VA, VB, ϵ=0.01):\n",
    "    '''Psychometric function which converts the decision variable (VB-VA)\n",
    "    into a reponse probability. Output corresponds to probability of choosing\n",
    "    the delayed reward (option B).'''\n",
    "    return ϵ + (1.0-2.0*ϵ) * (1/(1+pm.math.exp(-1.7*(VB-VA))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Update the Φ function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def participant_group_lookup(trial_level_dataset):\n",
    "    # create a group lookup table. 1 entry for each particpant\n",
    "    temp = np.array([trial_level_dataset['id'].values, trial_level_dataset['group'].values]).T\n",
    "    temp = np.unique(temp, axis=0)\n",
    "    group = temp[:,1]\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_modified_rachlin_model(trial_level_dataset):\n",
    "    '''Returns a PyMC3 model which does inference on discounting parameters from participants\n",
    "    from two groups. We have hierachical inference at the group level and we are essentially doing\n",
    "    a Bayesian t-test where we estimate Cohen's D effect size'''\n",
    "    \n",
    "    # extract data from DataFrame\n",
    "    DA = trial_level_dataset.DA.values\n",
    "    RA = trial_level_dataset.RA.values\n",
    "    DB = trial_level_dataset.DB.values\n",
    "    RB = trial_level_dataset.RB.values\n",
    "    R = trial_level_dataset.R.values\n",
    "    id = trial_level_dataset.id.values\n",
    "    \n",
    "    group = participant_group_lookup(trial_level_dataset)\n",
    "    \n",
    "    n_participants = np.max(trial_level_dataset.id) + 1\n",
    "    n_groups = 2\n",
    "     \n",
    "#     # use actual mean and std as parameters for the prior\n",
    "#     μ_m = y.value.mean()\n",
    "#     μ_s = y.value.std() * 2\n",
    "\n",
    "    σ_low = 0\n",
    "    σ_high = 10\n",
    "    \n",
    "    # Start building the model from the top down, starting with Bayesian t-test\n",
    "    with pm.Model() as model:\n",
    "        logκ_group_means = pm.Normal('logκ_group_means', mu=-3, sd=0.1, shape=n_groups)\n",
    "        logκ_group_stds = pm.Uniform('logκ_group_stds', lower=σ_low, upper=σ_high, shape=n_groups)\n",
    "#         group_logk = pm.Normal('group_logk', mu=group_means, sd=group_stds, shape=n_groups)\n",
    "\n",
    "        logs_group_means = pm.Normal('logs_group_means', mu=1, sd=0.1, shape=n_groups)\n",
    "        logs_group_stds = pm.Uniform('logs_group_stds', lower=σ_low, upper=σ_high, shape=n_groups)\n",
    "            \n",
    "    # compute measures about the group level estimates of logk\n",
    "    with model:\n",
    "        logκ_diff_of_means = pm.Deterministic('logκ difference of means', logκ_group_means[0] - logκ_group_means[1])\n",
    "        logκ_diff_of_stds = pm.Deterministic('logκ difference of stds', logκ_group_stds[0] - logκ_group_stds[1])\n",
    "        logκ_effect_size = pm.Deterministic('logκ effect size',\n",
    "                                       logκ_diff_of_means / np.sqrt((logκ_group_stds[0]**2 + logκ_group_stds[1]**2) / 2))\n",
    "        \n",
    "        logs_diff_of_means = pm.Deterministic('logs difference of means', logs_group_means[0] - logs_group_means[1])\n",
    "        logs_diff_of_stds = pm.Deterministic('logs difference of stds', logs_group_stds[0] - logs_group_stds[1])\n",
    "        logs_effect_size = pm.Deterministic('logs effect size',\n",
    "                                       logs_diff_of_means / np.sqrt((logs_group_stds[0]**2 + logs_group_stds[1]**2) / 2))\n",
    "        \n",
    "    # Discounting part of the model\n",
    "    with model:\n",
    "        # priors over parameters for each participant\n",
    "        logκ = pm.Normal('logκ', mu=logκ_group_means[group], sd=logκ_group_stds[group], shape=n_participants)\n",
    "        logs = pm.Normal('logs', mu=logs_group_means[group], sd=logs_group_stds[group], shape=n_participants)\n",
    "        \n",
    "        # Choice function: psychometric\n",
    "        P = pm.Deterministic('P', Φ(V(RA, DA, logκ[id], logs[id]),\n",
    "                                    V(RB, DB, logκ[id], logs[id])) )\n",
    "        # Likelihood of observations\n",
    "        R = pm.Bernoulli('R', p=P, observed=R)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High level code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define true things about the experiment and groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 20\n",
    "# groupA = {'κ_mean': 0.01, 's_mean':1, 's_std': 0.01}\n",
    "# groupA = {'κ_mean': 0.001, 's_mean':1, 's_std': 0.01}\n",
    "\n",
    "# # we iterate of over effect sizes. This is implimented by changing the std on kappa\n",
    "# group_κstd_list = np.linspace(0.0001, 0.01, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test code to do inference for a given effect size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_logκstd = 0.01\n",
    "\n",
    "participant_level_dataset, true_κ_effect_size = make_participant_level_dataset(group_logκstd,\n",
    "                                   groupA_logκmean=-4.6, \n",
    "                                   groupB_logκmean=-2.3,\n",
    "                                   groupA_logsmean=0, \n",
    "                                   groupB_logsmean=0,\n",
    "                                   logs_std=0.1,\n",
    "                                   N_per_group=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_level_dataset = simulate_entire_experiment(participant_level_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_modified_rachlin_model(trial_level_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO THE INFERENCE\n",
    "with model:\n",
    "    trace = pm.sample(**sample_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.energyplot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace, var_names=['logκ'], r_hat=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace, var_names=['logs'], r_hat=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace, var_names=['logκ_group_means', 'logκ_group_stds']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace, var_names=['logs_group_means', 'logs_group_stds'], r_hat=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace, var_names=['logκ difference of means','logκ difference of stds', 'logκ effect size'],\n",
    "                  ref_val=0,\n",
    "                  color='#87ceeb');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace, var_names=['logs difference of means','logs difference of stds', 'logs effect size'],\n",
    "                  ref_val=0,\n",
    "                  color='#87ceeb');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want something along these lines...\n",
    "\n",
    "Iterate over true effect size, estimating the effect size from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_real = []\n",
    "es_inferred = {}\n",
    "\n",
    "for group_κstd in group_κstd_list:\n",
    "    \n",
    "    # make true participant level dataset of parameter values\n",
    "    participant_level_dataset, true_κ_effect_size = make_participant_level_dataset(group_κstd)\n",
    "    \n",
    "    # simulate and entire experiment\n",
    "    trial_level_dataset = simulate_entire_experiment(participant_level_dataset)\n",
    "    \n",
    "    # conduct Bayesian inference on parameters\n",
    "    # This will be a row for each participant, columns include inferred\n",
    "    inferred_effect_size = bayesian_effect_size_from_discounting_data(trial_level_dataset)\n",
    "    \n",
    "    # Store true effect size\n",
    "    es_real.append(true_κ_effect_size)\n",
    "    \n",
    "    # Store posterior median and 95% CI of effect sizes\n",
    "    es_inferred['point_estimate'] = es_inferred['point_estimate'].append(inferred_effect_size['point_estimate'])\n",
    "    es_inferred['2.5'] = es_inferred['2.5'].append(inferred_effect_size['2.5'])\n",
    "    es_inferred['97.5'] = es_inferred['97.5'].append(inferred_effect_size['97.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT RESULTS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- Kruschke, John. (2012) Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
